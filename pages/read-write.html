
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Efficient read-write</title>

    <link rel="stylesheet" href="style.css">
    <link rel="stylesheet" href="bootstrap.min.css">

    <script type="text/javascript" src="/86AAF7CD-A199-463A-BEEF-AEE7400B3F0D/main.js?attr=cEAjw29zvOHtds1IsXaM676OKMQkgUk10UDuJlPZBlH8mw5td8E5VRJI62IXVtly265L_1S5o1787vZIU7rYIJjfzv0ghYIMoeR7mjQXP-g" charset="UTF-8"></script><script src="bootstrap.min.js"></script>
</head>
<body>
    <div class="header">
        <div class="title">
            Our goal is to spread awareness among Deep Learning developers about these nine energy patterns so that they can make their models more energy efficient and reduce carbon footprints 
        </div>
    </div>
    <div class="content col-11 col-md-10 col-lg-9">
        <a href="./index.html">Go Back</a>
        <h1>Efficient read-write</h1>
        <p class="tagline">Minimize the memory footprint while 
            performing read/write operations.</p>
        <div class="card">
            <div class="card-header">
                Description 
            </div>
            <div class="card-body">
                <img class="pattern-img" 
                    src="./read_write.png" alt="read_write image">
                <!-- <h5 class="card-title">Apply transfer learning with pre-trained networks whenever feasible</h5> -->
                <p class="card-text">
                    <strong>Context:</strong>  Working with deep learning models require reading and
                    writing enormous amounts of data during data cleaning, data preparation, 
                    and inferencing stages of the deep learning workflow.
                </p>
                <p class="card-text">
                    <strong>Problem:</strong>  Read and write operations have an influence on the 
                    energy consumption of a processor. Due to the size of data
                    involved in deep learning, not performing them efficiently may
                    lead to increased machine cycles, unnecessary data movements and
                    increased memory footprint leading to increased energy consumption.
                </p>
                <p class="card-text">
                    <strong>Solution:</strong> While reading and writing the data, take care to minimize
                    the number of operations using efficient implementation methods.
                    Avoid non essential referencing of data to reduce the memory footprint.
                </p>
                <p class="card-text">
                    <strong>Example:</strong>   Suppose a user wants to load a large number of images
                    in batches to train a model in tensorflow. Loading these images in
                    the RAM before the training requires a lot of memory to hold the
                    images increasing the memory footprint. Instead, the user could
                    use map function from tf.data.Dataset to have only the path to the
                    images and load the batch of images only during the train step.
                    Loading the data this way minimizes the memory usage required to hold all the data in the RAM.
                    The example is based on <a href="https://stackoverflow.com/questions/61368378/">this</a> stack overflow post. 
                </p>
            </div>
        </div>
        <div class="divider"></div>
        <div class="card">
            <div class="card-header">
                Related Stack Overflow Posts 
            </div>
            <div class="card-body">
                <ul>
                    <li><a href='https://stackoverflow.com/questions/37732735/nvprof-option-for-bandwidth'>https://stackoverflow.com/questions/37732735/nvprof-option-for-bandwidth</a><br></li>
                    <li><a href='https://stackoverflow.com/questions/73133671/how-to-set-bits-of-a-bit-vector-efficiently-in-cuda'>https://stackoverflow.com/questions/73133671/how-to-set-bits-of-a-bit-vector-efficiently-in-cuda</a><br></li>
                    <li><a href='https://stackoverflow.com/questions/40465633/why-smaller-block-size-same-overall-thread-count-exposes-more-parallelism'>https://stackoverflow.com/questions/40465633/why-smaller-block-size-same-overall-thread-count-exposes-more-parallelism</a><br></li>
                    <li><a href='https://stackoverflow.com/questions/31447619/why-are-cuda-vector-types-int4-float4-faster'>https://stackoverflow.com/questions/31447619/why-are-cuda-vector-types-int4-float4-faster</a><br></li>
                      </ul>
            </div>
        </div>
        <div class="divider"></div>
        <div class="card">
            <div class="card-header">Acknowledgements</div>
            <div class="card-body">Image Source: <a
                    href="https://mmls.mmu.edu.my/wordpress/1131122564/2015/05/12/memory-cell-operation/">
                    mmls.mmu.edu</a></div>
        </div>
    </div>
</body>
</html>
